{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dried-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "path = \"UnderWaterGAN_pytorch/imgs/\"\n",
    "\n",
    "dirt = os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UnderWaterGAN_pytorch/imgs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prospective-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the diretory exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dirt):\n",
    "    print(\"the directory is not exists\")\n",
    "else:\n",
    "    print(\"the diretory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "polish-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (tensor) --  the input image tensor array\n",
    "        imtype (type)        --  the desired type of the converted numpy array\n",
    "    \"\"\"\n",
    "    if not isinstance(input_image, np.ndarray):\n",
    "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
    "            image_tensor = input_image.data\n",
    "        else:\n",
    "            return input_image\n",
    "        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n",
    "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
    "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
    "    else:  # if it is a numpy array, do nothing\n",
    "        image_numpy = input_image\n",
    "    return image_numpy.astype(imtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "common-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img = Image.open(\"UnderWaterGAN_pytorch/imgs/Picturea1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "relative-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "gross-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039,  ..., 0.0118, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0039, 0.0235,  ..., 0.0510, 0.0078, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0235, 0.0941,  ..., 0.0196, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0078, 0.0235,  ..., 0.0039, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0078,  ..., 0.0118, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0078, 0.0392,  ..., 0.0549, 0.0078, 0.0000],\n",
       "         ...,\n",
       "         [0.0039, 0.0275, 0.1098,  ..., 0.0431, 0.0118, 0.0000],\n",
       "         [0.0000, 0.0078, 0.0275,  ..., 0.0118, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0078,  ..., 0.0118, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0039, 0.0314,  ..., 0.0510, 0.0078, 0.0000],\n",
       "         ...,\n",
       "         [0.0039, 0.0275, 0.0941,  ..., 0.0549, 0.0157, 0.0039],\n",
       "         [0.0000, 0.0078, 0.0235,  ..., 0.0118, 0.0039, 0.0039],\n",
       "         [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0039, 0.0039]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_tensor(img).share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "removable-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToTensor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2im(convert_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-biography",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (torch-gpu)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
